"""NIST AI 600-1 (Generative AI Profile) deep assessment module.

Extends the base NIST AI RMF framework with GenAI-specific risk categories
defined in NIST AI 600-1.  This profile addresses risks unique to generative
AI systems, including confabulation, data privacy, information integrity,
CBRN information access, and value-chain integration concerns.

The module defines 12 risk categories, each containing actionable items
mapped to the four core NIST AI RMF functions (GOVERN, MAP, MEASURE, MANAGE).

Reference: https://airc.nist.gov/Docs/1
"""

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any

from aisec.core.enums import NistAiRmfFunction, Severity
from aisec.core.models import (
    AgentResult,
    ComplianceChecklist,
    ComplianceCheckItem,
    Finding,
)

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# Data structures
# ---------------------------------------------------------------------------


@dataclass
class ActionItem:
    """A single recommended action within a NIST AI 600-1 risk category."""

    id: str
    description: str
    rmf_function: NistAiRmfFunction
    priority: str = "recommended"  # "required", "recommended", "optional"


@dataclass
class RiskCategory:
    """A GenAI-specific risk category from NIST AI 600-1."""

    id: str
    name: str
    description: str
    action_items: list[ActionItem] = field(default_factory=list)


# ---------------------------------------------------------------------------
# 1. CBRN Information (Chemical, Biological, Radiological, Nuclear)
# ---------------------------------------------------------------------------

CBRN_INFORMATION = RiskCategory(
    id="GAI-1",
    name="CBRN Information",
    description=(
        "Generative AI systems may lower barriers for non-experts seeking to "
        "acquire or synthesise chemical, biological, radiological, or nuclear "
        "(CBRN) materials by providing detailed procedural knowledge, synthesis "
        "routes, or procurement guidance that is otherwise difficult to obtain."
    ),
    action_items=[
        ActionItem(
            id="GAI-1.01",
            description=(
                "Establish policies restricting the generation of content "
                "related to CBRN synthesis, procurement, or weaponisation."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-1.02",
            description=(
                "Implement content classifiers that detect CBRN-related queries "
                "and route them to human review or automated refusal pipelines."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-1.03",
            description=(
                "Map training data sources for CBRN-adjacent information and "
                "evaluate whether the model retains actionable synthesis knowledge."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-1.04",
            description=(
                "Red-team the model with domain experts to assess its ability "
                "to provide uplift for CBRN weapon development."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-1.05",
            description=(
                "Define escalation procedures when CBRN-related content "
                "generation is detected in production."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-1.06",
            description=(
                "Maintain a CBRN keyword and concept blocklist updated with "
                "guidance from relevant national security agencies."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-1.07",
            description=(
                "Assess the dual-use potential of chemistry, biology, and "
                "materials science outputs generated by the model."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-1.08",
            description=(
                "Benchmark the model against known CBRN evaluation datasets to "
                "quantify information leakage risk."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-1.09",
            description=(
                "Deploy output filters specifically trained to detect step-by-step "
                "instructions for synthesising hazardous substances."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-1.10",
            description=(
                "Conduct periodic reviews of CBRN-related refusal rates and "
                "false-positive impacts on legitimate scientific research queries."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-1.11",
            description=(
                "Engage biosecurity and chemical safety experts in threat "
                "modelling for the generative AI system."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-1.12",
            description=(
                "Document the organisation's risk tolerance for CBRN "
                "information generation and communicate it to all stakeholders."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-1.13",
            description=(
                "Implement logging and audit trails for all queries flagged as "
                "CBRN-related for post-incident investigation."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-1.14",
            description=(
                "Train content moderation teams on CBRN domain knowledge so "
                "they can accurately evaluate flagged outputs."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-1.15",
            description=(
                "Evaluate whether fine-tuning or retrieval augmentation "
                "inadvertently introduces new CBRN knowledge into the system."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-1.16",
            description=(
                "Coordinate with law-enforcement and intelligence community "
                "liaisons regarding reports of CBRN misuse attempts."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-1.17",
            description=(
                "Identify which model capabilities could be exploited for "
                "radiological device design or nuclear enrichment guidance."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 2. Confabulation / Hallucination
# ---------------------------------------------------------------------------

CONFABULATION = RiskCategory(
    id="GAI-2",
    name="Confabulation / Hallucination",
    description=(
        "Generative AI systems can produce outputs that are plausible-sounding "
        "but factually incorrect, fabricated, or inconsistent with the input "
        "context.  Such confabulations pose risks when users rely on AI-generated "
        "content for decision-making, legal, medical, or financial advice."
    ),
    action_items=[
        ActionItem(
            id="GAI-2.01",
            description=(
                "Establish organisational policies defining acceptable "
                "hallucination rates for different deployment contexts."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-2.02",
            description=(
                "Identify use cases where confabulation risk is highest and "
                "document the potential impact of incorrect outputs."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-2.03",
            description=(
                "Implement retrieval-augmented generation (RAG) with source "
                "attribution to ground outputs in verifiable data."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-2.04",
            description=(
                "Benchmark the model on factuality and hallucination detection "
                "datasets across targeted knowledge domains."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-2.05",
            description=(
                "Deploy real-time fact-checking pipelines that verify key "
                "claims in generated outputs against trusted knowledge bases."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-2.06",
            description=(
                "Provide confidence scores or uncertainty indicators alongside "
                "generated outputs so users can assess reliability."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-2.07",
            description=(
                "Map the domains in which the model is most prone to "
                "confabulation based on training data coverage analysis."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-2.08",
            description=(
                "Measure hallucination frequency using automated metrics "
                "such as faithfulness scores and entailment checks."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-2.09",
            description=(
                "Train end users to critically evaluate AI-generated content "
                "and verify claims before acting on them."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-2.10",
            description=(
                "Implement feedback mechanisms allowing users to report "
                "confabulated outputs for model improvement."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-2.11",
            description=(
                "Conduct adversarial testing to identify prompt patterns "
                "that reliably induce hallucination."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-2.12",
            description=(
                "Evaluate the impact of decoding parameters (temperature, "
                "top-p) on hallucination rates in production settings."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-2.13",
            description=(
                "Document known failure modes and communicate confabulation "
                "limitations in user-facing documentation."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-2.14",
            description=(
                "Implement chain-of-thought verification where the model's "
                "reasoning steps are checked for logical consistency."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-2.15",
            description=(
                "Monitor production outputs for confabulation trends using "
                "automated sampling and human evaluation loops."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-2.16",
            description=(
                "Assess whether confabulated legal citations, medical advice, "
                "or financial data could create liability for the organisation."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-2.17",
            description=(
                "Require human review of generated content in high-stakes "
                "applications such as healthcare, law, and finance."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-2.18",
            description=(
                "Validate that RAG retrieval pipelines return relevant "
                "and up-to-date documents to reduce grounding errors."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 3. Data Privacy
# ---------------------------------------------------------------------------

DATA_PRIVACY = RiskCategory(
    id="GAI-3",
    name="Data Privacy",
    description=(
        "Generative AI systems may memorise and reproduce personal, sensitive, "
        "or proprietary information from their training data.  They may also "
        "inadvertently collect, process, or expose user data in ways that "
        "violate privacy regulations or user expectations."
    ),
    action_items=[
        ActionItem(
            id="GAI-3.01",
            description=(
                "Establish data governance policies specific to generative AI "
                "training data, including personal data handling requirements."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-3.02",
            description=(
                "Inventory all personal and sensitive data present in training, "
                "fine-tuning, and retrieval-augmentation datasets."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-3.03",
            description=(
                "Implement differential privacy or other privacy-preserving "
                "techniques during model training."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-3.04",
            description=(
                "Test for memorisation of training data using membership "
                "inference and data extraction attacks."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-3.05",
            description=(
                "Deploy output filters that detect and redact personal "
                "identifiable information (PII) in generated content."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-3.06",
            description=(
                "Conduct privacy impact assessments (PIAs) before deploying "
                "generative AI systems that process user data."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-3.07",
            description=(
                "Implement data minimisation principles: collect only the "
                "user data necessary for the system's function."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-3.08",
            description=(
                "Measure the rate at which the model reproduces verbatim "
                "training data across different prompt strategies."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-3.09",
            description=(
                "Provide users with transparency about what data is collected "
                "during interactions and how it is used."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-3.10",
            description=(
                "Implement data retention policies for user interaction logs "
                "and ensure timely deletion per regulatory requirements."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-3.11",
            description=(
                "Assess cross-border data transfer implications when the "
                "generative AI system serves users in multiple jurisdictions."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-3.12",
            description=(
                "Evaluate whether model unlearning or data deletion requests "
                "can be effectively honoured post-training."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-3.13",
            description=(
                "Implement consent management for user data used in model "
                "improvement or fine-tuning pipelines."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-3.14",
            description=(
                "Audit third-party data providers for compliance with privacy "
                "regulations and contractual data-use obligations."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-3.15",
            description=(
                "Monitor for prompt injection attacks that aim to extract "
                "private data memorised by the model."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-3.16",
            description=(
                "Benchmark PII leakage rates before and after applying "
                "privacy-preserving mitigations."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-3.17",
            description=(
                "Establish breach notification procedures for incidents where "
                "generative AI exposes personal data."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 4. Environmental Impact
# ---------------------------------------------------------------------------

ENVIRONMENTAL_IMPACT = RiskCategory(
    id="GAI-4",
    name="Environmental Impact",
    description=(
        "The training, fine-tuning, and inference of generative AI models "
        "consume substantial computational resources, leading to significant "
        "energy consumption, carbon emissions, and water usage.  Organisations "
        "should quantify and mitigate these environmental costs."
    ),
    action_items=[
        ActionItem(
            id="GAI-4.01",
            description=(
                "Establish organisational policies requiring measurement and "
                "reporting of AI-related energy consumption and carbon emissions."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-4.02",
            description=(
                "Map the computational footprint of all generative AI workloads, "
                "including training, fine-tuning, and inference."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-4.03",
            description=(
                "Measure energy consumption per inference request and track "
                "trends over time and across model versions."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-4.04",
            description=(
                "Implement model efficiency optimisations such as distillation, "
                "quantisation, and pruning to reduce computational requirements."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-4.05",
            description=(
                "Evaluate the environmental impact of model selection decisions "
                "and prefer smaller models when performance is adequate."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-4.06",
            description=(
                "Benchmark carbon emissions against industry baselines and "
                "set reduction targets for AI infrastructure."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-4.07",
            description=(
                "Prioritise renewable energy sources for data centres hosting "
                "generative AI workloads."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-4.08",
            description=(
                "Require environmental impact disclosures when procuring "
                "third-party generative AI services."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-4.09",
            description=(
                "Assess water usage for cooling at data centres running "
                "large-scale generative AI training jobs."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-4.10",
            description=(
                "Track the total lifecycle carbon footprint including hardware "
                "manufacturing and end-of-life disposal."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-4.11",
            description=(
                "Implement request batching and caching strategies to reduce "
                "redundant inference computations."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-4.12",
            description=(
                "Report environmental metrics in organisational sustainability "
                "disclosures and regulatory filings."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-4.13",
            description=(
                "Evaluate trade-offs between model accuracy and environmental "
                "cost during model selection and deployment decisions."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-4.14",
            description=(
                "Measure and compare the environmental cost of retraining "
                "versus fine-tuning versus in-context learning approaches."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-4.15",
            description=(
                "Implement auto-scaling policies that minimise idle GPU "
                "consumption during low-demand periods."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-4.16",
            description=(
                "Set organisational targets for power usage effectiveness (PUE) "
                "at AI-dedicated data centres."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 5. Harmful Bias and Homogenization
# ---------------------------------------------------------------------------

HARMFUL_BIAS = RiskCategory(
    id="GAI-5",
    name="Harmful Bias and Homogenization",
    description=(
        "Generative AI systems can amplify historical biases present in training "
        "data, producing outputs that discriminate against protected groups.  "
        "Additionally, widespread adoption of similar models can homogenise "
        "cultural expression, reduce diversity of viewpoints, and entrench "
        "dominant narratives at the expense of marginalised perspectives."
    ),
    action_items=[
        ActionItem(
            id="GAI-5.01",
            description=(
                "Establish bias and fairness policies that define unacceptable "
                "disparate impact thresholds for generative AI outputs."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-5.02",
            description=(
                "Map the demographic and cultural composition of training "
                "datasets to identify representation gaps."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-5.03",
            description=(
                "Benchmark model outputs across protected attributes (gender, "
                "race, age, disability) using standardised fairness metrics."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-5.04",
            description=(
                "Implement bias mitigation techniques such as debiasing "
                "embeddings, balanced sampling, and adversarial debiasing."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-5.05",
            description=(
                "Assess how the model represents historically marginalised "
                "communities and whether outputs reinforce stereotypes."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-5.06",
            description=(
                "Measure the diversity of generated outputs to detect "
                "homogenisation effects (e.g., all images showing the same skin tone)."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-5.07",
            description=(
                "Establish external advisory boards with diverse community "
                "representation to review bias evaluation results."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-5.08",
            description=(
                "Deploy bias detection classifiers that flag potentially "
                "discriminatory outputs in real time."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-5.09",
            description=(
                "Conduct intersectional bias analysis examining compounding "
                "effects across multiple protected attributes."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-5.10",
            description=(
                "Evaluate downstream impacts of homogenised outputs on "
                "creative industries, education, and cultural expression."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-5.11",
            description=(
                "Implement user reporting mechanisms for biased or offensive "
                "outputs and feed reports into model improvement cycles."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-5.12",
            description=(
                "Require bias impact assessments before deploying generative "
                "AI in high-impact domains such as hiring, lending, or healthcare."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-5.13",
            description=(
                "Track bias metrics over time to detect drift and ensure "
                "mitigations remain effective as the model evolves."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-5.14",
            description=(
                "Assess whether the model's language capabilities introduce "
                "bias against non-English speakers or low-resource languages."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-5.15",
            description=(
                "Implement prompt engineering guidelines that reduce the "
                "likelihood of biased outputs in production deployments."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-5.16",
            description=(
                "Document known bias limitations and communicate them "
                "transparently to downstream consumers and users."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-5.17",
            description=(
                "Evaluate the use of diverse annotator pools during "
                "reinforcement learning from human feedback (RLHF) to reduce "
                "evaluator bias."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-5.18",
            description=(
                "Assess monoculture risk when multiple downstream applications "
                "rely on the same foundation model."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 6. Human-AI Configuration
# ---------------------------------------------------------------------------

HUMAN_AI_CONFIGURATION = RiskCategory(
    id="GAI-6",
    name="Human-AI Configuration",
    description=(
        "Improper configuration of the human-AI interaction can lead to over-"
        "reliance on AI outputs, automation bias, loss of human oversight, and "
        "degradation of human skills.  The design of human-AI teaming must "
        "preserve meaningful human control and decision-making authority."
    ),
    action_items=[
        ActionItem(
            id="GAI-6.01",
            description=(
                "Establish governance policies defining when human oversight "
                "is mandatory for AI-generated decisions and content."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-6.02",
            description=(
                "Map all decision points where AI outputs influence consequential "
                "human decisions and assess the level of human control."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-6.03",
            description=(
                "Measure user over-reliance on AI outputs through studies "
                "comparing human accuracy with and without AI assistance."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-6.04",
            description=(
                "Implement human-in-the-loop approval gates for high-stakes "
                "actions initiated by generative AI systems."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-6.05",
            description=(
                "Design user interfaces that clearly distinguish AI-generated "
                "content from human-authored content."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-6.06",
            description=(
                "Assess the risk of automation bias where users uncritically "
                "accept AI recommendations."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-6.07",
            description=(
                "Measure the impact of AI assistance on human skill retention "
                "and cognitive engagement over time."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-6.08",
            description=(
                "Provide training programmes that teach users how to "
                "effectively collaborate with generative AI systems."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-6.09",
            description=(
                "Implement fallback mechanisms that allow humans to override "
                "or correct AI-generated outputs at any stage."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-6.10",
            description=(
                "Evaluate whether the AI system's response latency and "
                "interaction design support effective human deliberation."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-6.11",
            description=(
                "Map scenarios where human oversight failure could lead to "
                "significant harm and implement additional safeguards."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-6.12",
            description=(
                "Define clear roles and responsibilities for human operators "
                "interacting with autonomous AI agent systems."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-6.13",
            description=(
                "Implement monitoring for signs of human de-skilling in teams "
                "heavily reliant on generative AI tools."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-6.14",
            description=(
                "Design escalation paths from automated AI decisions to human "
                "reviewers for edge cases and uncertain outputs."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-6.15",
            description=(
                "Assess the cognitive load placed on human reviewers and "
                "ensure it remains manageable for effective oversight."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-6.16",
            description=(
                "Establish periodic human calibration exercises where "
                "reviewers evaluate AI outputs without knowing the source."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-6.17",
            description=(
                "Document the intended level of autonomy for the AI system "
                "and ensure it is communicated to all users."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 7. Information Integrity
# ---------------------------------------------------------------------------

INFORMATION_INTEGRITY = RiskCategory(
    id="GAI-7",
    name="Information Integrity",
    description=(
        "Generative AI can be used to produce and disseminate disinformation, "
        "deepfakes, and manipulative content at scale.  This threatens the "
        "integrity of the information ecosystem, erodes public trust, and "
        "can be weaponised for political manipulation, fraud, and social "
        "engineering attacks."
    ),
    action_items=[
        ActionItem(
            id="GAI-7.01",
            description=(
                "Establish policies prohibiting the use of the generative AI "
                "system for creating disinformation or deceptive content."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-7.02",
            description=(
                "Map threat scenarios where the system could be misused to "
                "generate deepfakes, fake news, or impersonation content."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-7.03",
            description=(
                "Implement content provenance mechanisms such as C2PA metadata "
                "or watermarking for all AI-generated outputs."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-7.04",
            description=(
                "Measure the effectiveness of watermarking and detection tools "
                "against adversarial removal attempts."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-7.05",
            description=(
                "Deploy automated detection systems that identify AI-generated "
                "content in incoming data streams and user submissions."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-7.06",
            description=(
                "Assess the system's potential for generating convincing "
                "synthetic media (audio, video, images) that could deceive humans."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-7.07",
            description=(
                "Benchmark deepfake detection capabilities against state-of-the-art "
                "synthetic media generation techniques."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-7.08",
            description=(
                "Implement rate limiting and abuse detection for API access "
                "to prevent large-scale disinformation campaigns."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-7.09",
            description=(
                "Require disclosure of AI-generated content in user-facing "
                "applications and communications."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-7.10",
            description=(
                "Map the potential for the system to be used in influence "
                "operations targeting elections, public health, or markets."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-7.11",
            description=(
                "Measure user ability to distinguish AI-generated content "
                "from authentic content in controlled evaluation studies."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-7.12",
            description=(
                "Implement know-your-customer (KYC) requirements for high-volume "
                "API consumers to deter misuse for disinformation."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-7.13",
            description=(
                "Collaborate with platform operators and fact-checkers to "
                "share intelligence on AI-generated disinformation."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-7.14",
            description=(
                "Assess the system's vulnerability to being used for automated "
                "social engineering and phishing campaigns."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-7.15",
            description=(
                "Evaluate the robustness of content provenance metadata against "
                "tampering and stripping attacks."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-7.16",
            description=(
                "Implement logging and traceability for content generation "
                "requests to support forensic investigation of misuse."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-7.17",
            description=(
                "Establish incident response procedures for when AI-generated "
                "disinformation is traced back to the organisation's system."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-7.18",
            description=(
                "Assess the cumulative impact of AI-generated content on "
                "information ecosystem health and public discourse quality."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 8. Information Security
# ---------------------------------------------------------------------------

INFORMATION_SECURITY = RiskCategory(
    id="GAI-8",
    name="Information Security",
    description=(
        "Generative AI systems introduce novel information security risks "
        "including prompt injection, training data poisoning, model theft, "
        "adversarial examples, and side-channel attacks on inference APIs.  "
        "Traditional cybersecurity controls must be augmented with AI-specific "
        "defences."
    ),
    action_items=[
        ActionItem(
            id="GAI-8.01",
            description=(
                "Establish security policies covering AI-specific attack "
                "vectors including prompt injection, model extraction, and "
                "training data poisoning."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-8.02",
            description=(
                "Map the AI system's attack surface including model APIs, "
                "training pipelines, tool integrations, and data ingestion points."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-8.03",
            description=(
                "Implement input validation and sanitisation to detect and "
                "block prompt injection attempts."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-8.04",
            description=(
                "Measure the system's resilience against prompt injection using "
                "automated red-team testing with diverse attack payloads."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-8.05",
            description=(
                "Deploy output filtering to prevent the model from leaking "
                "system prompts, API keys, or internal configuration."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-8.06",
            description=(
                "Assess the risk of model weight theft through API-based "
                "model extraction attacks."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-8.07",
            description=(
                "Benchmark adversarial robustness against known evasion "
                "techniques for the model architecture in use."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-8.08",
            description=(
                "Implement access controls and authentication for all model "
                "endpoints, training infrastructure, and data stores."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-8.09",
            description=(
                "Conduct supply chain security assessments for pre-trained "
                "models, libraries, and datasets sourced externally."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-8.10",
            description=(
                "Measure side-channel leakage through inference API response "
                "times, token probabilities, and error messages."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-8.11",
            description=(
                "Implement rate limiting and anomaly detection on inference "
                "APIs to detect model extraction and abuse patterns."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-8.12",
            description=(
                "Define security requirements for the entire ML pipeline: "
                "data collection, training, evaluation, and deployment."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-8.13",
            description=(
                "Assess the integrity of training data against backdoor "
                "and data poisoning attacks."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-8.14",
            description=(
                "Test for indirect prompt injection through retrieval-augmented "
                "generation data sources and tool outputs."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-8.15",
            description=(
                "Implement secure model serving infrastructure with encryption "
                "in transit, at rest, and during computation where feasible."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-8.16",
            description=(
                "Require security reviews and penetration testing before "
                "deploying generative AI systems to production."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-8.17",
            description=(
                "Implement continuous security monitoring for AI-specific "
                "indicators of compromise in production systems."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-8.18",
            description=(
                "Measure the effectiveness of security controls against "
                "emerging AI attack techniques through periodic assessments."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-8.19",
            description=(
                "Map dependencies on external model providers and assess "
                "single-points-of-failure in the AI infrastructure."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-8.20",
            description=(
                "Establish vulnerability disclosure programmes that include "
                "AI-specific attack vectors and model vulnerabilities."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 9. Intellectual Property
# ---------------------------------------------------------------------------

INTELLECTUAL_PROPERTY = RiskCategory(
    id="GAI-9",
    name="Intellectual Property",
    description=(
        "Generative AI systems may infringe on intellectual property rights by "
        "reproducing copyrighted material, generating content that is "
        "substantially similar to protected works, or using proprietary data "
        "in training without authorisation.  Organisations face legal and "
        "reputational risks from IP violations."
    ),
    action_items=[
        ActionItem(
            id="GAI-9.01",
            description=(
                "Establish policies governing the use of copyrighted material "
                "in training data and the IP status of generated outputs."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-9.02",
            description=(
                "Inventory all training data sources and assess their "
                "licensing terms, copyright status, and usage restrictions."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-9.03",
            description=(
                "Implement near-duplicate detection to identify when generated "
                "outputs closely match copyrighted training data."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-9.04",
            description=(
                "Measure the frequency with which the model reproduces "
                "copyrighted text, code, or artistic works verbatim."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-9.05",
            description=(
                "Assess the legal landscape for AI-generated content IP "
                "ownership in all jurisdictions where the system operates."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-9.06",
            description=(
                "Implement opt-out mechanisms for content creators who do not "
                "want their works used in AI training."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-9.07",
            description=(
                "Benchmark the model's tendency to memorise and reproduce "
                "code snippets from specific open-source licences."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-9.08",
            description=(
                "Deploy output attribution systems that identify potential "
                "source material for generated content."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-9.09",
            description=(
                "Define clear terms of service regarding IP ownership of "
                "content generated by the AI system for end users."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-9.10",
            description=(
                "Map potential trade secret exposure risks when the model is "
                "fine-tuned on proprietary organisational data."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-9.11",
            description=(
                "Measure the similarity between generated outputs and known "
                "copyrighted works using embedding-based similarity metrics."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-9.12",
            description=(
                "Implement guardrails that refuse requests to reproduce "
                "specific copyrighted works or impersonate named artists."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-9.13",
            description=(
                "Maintain records of training data provenance to support "
                "legal defence in IP infringement claims."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-9.14",
            description=(
                "Assess the risk of generated code introducing licence "
                "contamination (e.g., GPL code in proprietary projects)."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-9.15",
            description=(
                "Evaluate the effectiveness of training data filtering in "
                "reducing IP infringement risk without degrading model quality."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-9.16",
            description=(
                "Implement content licensing verification for retrieval-augmented "
                "generation data sources."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-9.17",
            description=(
                "Establish indemnification and insurance arrangements for "
                "potential AI-related IP infringement claims."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 10. Obscene, Degrading, and/or Abusive Content
# ---------------------------------------------------------------------------

OBSCENE_CONTENT = RiskCategory(
    id="GAI-10",
    name="Obscene, Degrading, and/or Abusive Content",
    description=(
        "Generative AI systems can produce sexually explicit, degrading, "
        "harassing, or otherwise abusive content.  This includes non-consensual "
        "intimate imagery, child sexual abuse material (CSAM), hate speech, "
        "and targeted harassment content.  Robust content safety measures are "
        "essential."
    ),
    action_items=[
        ActionItem(
            id="GAI-10.01",
            description=(
                "Establish content safety policies with zero tolerance for CSAM "
                "and clear definitions of prohibited content categories."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-10.02",
            description=(
                "Map the types of harmful content the model is capable of "
                "generating, including text, images, audio, and code."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-10.03",
            description=(
                "Implement multi-layered content safety classifiers that detect "
                "and block harmful outputs before they reach users."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-10.04",
            description=(
                "Red-team the model to identify jailbreak techniques that "
                "bypass content safety filters."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-10.05",
            description=(
                "Assess the risk of the system being used to generate "
                "non-consensual intimate imagery of real individuals."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-10.06",
            description=(
                "Benchmark content safety filters against adversarial attacks "
                "including obfuscation, encoding tricks, and multi-turn prompting."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-10.07",
            description=(
                "Deploy CSAM detection tools (e.g., PhotoDNA, NCMEC hash lists) "
                "on all generated image outputs."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-10.08",
            description=(
                "Implement mandatory reporting procedures for CSAM detection "
                "in compliance with applicable laws."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-10.09",
            description=(
                "Measure content safety classifier accuracy, including false "
                "positive rates that may restrict legitimate use."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-10.10",
            description=(
                "Assess the potential for the system to be used for targeted "
                "harassment, bullying, or stalking campaigns."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-10.11",
            description=(
                "Implement user reporting mechanisms for harmful content "
                "and establish rapid response procedures."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-10.12",
            description=(
                "Train content moderation teams on the psychological impact "
                "of reviewing harmful AI-generated content and provide support."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-10.13",
            description=(
                "Evaluate whether fine-tuning on user data could introduce "
                "harmful content generation capabilities."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-10.14",
            description=(
                "Map cultural and jurisdictional variations in content "
                "acceptability standards for global deployments."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-10.15",
            description=(
                "Implement age verification or age-gating for access to "
                "generative AI systems that can produce mature content."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-10.16",
            description=(
                "Establish regular updates to content safety classifiers as "
                "new harmful content patterns emerge."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-10.17",
            description=(
                "Document and communicate content safety limitations to "
                "users and downstream integrators."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 11. Value Chain and Component Integration
# ---------------------------------------------------------------------------

VALUE_CHAIN = RiskCategory(
    id="GAI-11",
    name="Value Chain and Component Integration",
    description=(
        "Generative AI systems typically depend on complex value chains "
        "including pre-trained foundation models, fine-tuning datasets, "
        "plugin ecosystems, retrieval-augmentation sources, and third-party "
        "APIs.  Risks propagate across these dependencies and may be amplified "
        "at integration boundaries."
    ),
    action_items=[
        ActionItem(
            id="GAI-11.01",
            description=(
                "Establish supply chain security policies specific to AI "
                "components including models, datasets, and inference services."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-11.02",
            description=(
                "Map the complete value chain of all AI components, including "
                "foundation model providers, data vendors, and tool integrations."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-11.03",
            description=(
                "Implement software bill of materials (SBOM) and model cards "
                "for all AI components in the system."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-11.04",
            description=(
                "Measure the security posture of third-party AI components "
                "through vendor assessments and compliance audits."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-11.05",
            description=(
                "Assess the risk of supply chain attacks targeting pre-trained "
                "model weights, embeddings, or serialised pipelines."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-11.06",
            description=(
                "Implement integrity verification (checksums, signatures) for "
                "all downloaded models and datasets."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-11.07",
            description=(
                "Evaluate the impact of upstream model updates or deprecations "
                "on the system's security and functionality."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-11.08",
            description=(
                "Define contractual security requirements for all AI service "
                "providers and enforce them through regular audits."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-11.09",
            description=(
                "Map plugin and tool integration points as potential attack "
                "vectors for indirect prompt injection."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-11.10",
            description=(
                "Implement sandboxing and least-privilege access for third-party "
                "plugins and tool integrations."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-11.11",
            description=(
                "Measure the frequency and impact of upstream service "
                "disruptions on the AI system's availability and safety."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-11.12",
            description=(
                "Assess vendor lock-in risks and maintain contingency plans "
                "for switching AI service providers."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-11.13",
            description=(
                "Implement continuous monitoring of third-party API behaviour "
                "for unexpected changes that could affect system safety."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-11.14",
            description=(
                "Establish incident notification agreements with AI service "
                "providers for security events affecting shared components."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-11.15",
            description=(
                "Evaluate the trustworthiness of open-source model repositories "
                "and implement vetting procedures for community-contributed models."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-11.16",
            description=(
                "Map data flow across the value chain to identify where "
                "sensitive information crosses trust boundaries."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-11.17",
            description=(
                "Implement version pinning and rollback capabilities for all "
                "AI dependencies to manage regression risks."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-11.18",
            description=(
                "Define governance requirements for the lifecycle management "
                "of AI components from acquisition through decommissioning."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
    ],
)

# ---------------------------------------------------------------------------
# 12. Dangerous, Violent, or Hateful Content (including WMD)
# ---------------------------------------------------------------------------

DANGEROUS_CONTENT = RiskCategory(
    id="GAI-12",
    name="Dangerous, Violent, or Hateful Content",
    description=(
        "Generative AI systems can produce content that promotes violence, "
        "terrorism, self-harm, or hatred against individuals or groups.  This "
        "includes instructions for weapons of mass destruction (WMD), "
        "radicalisation material, and content that incites real-world violence.  "
        "Robust safeguards are needed to prevent these outputs."
    ),
    action_items=[
        ActionItem(
            id="GAI-12.01",
            description=(
                "Establish comprehensive policies prohibiting the generation "
                "of content promoting violence, terrorism, or self-harm."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-12.02",
            description=(
                "Map the types of dangerous content the model can generate, "
                "including weapons instructions, radicalisation material, and "
                "incitement to violence."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-12.03",
            description=(
                "Implement content safety classifiers specifically trained "
                "on violent, hateful, and dangerous content categories."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-12.04",
            description=(
                "Red-team the model with security experts to identify "
                "techniques for eliciting WMD-related instructions."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-12.05",
            description=(
                "Assess the model's capability to provide instructions for "
                "constructing improvised weapons or explosive devices."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-12.06",
            description=(
                "Benchmark the effectiveness of safety filters against known "
                "jailbreak techniques for dangerous content elicitation."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-12.07",
            description=(
                "Deploy multi-modal safety classifiers that detect dangerous "
                "content across text, images, audio, and video outputs."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-12.08",
            description=(
                "Implement mandatory law-enforcement reporting for detected "
                "attempts to generate WMD or terrorism-related content."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-12.09",
            description=(
                "Measure the model's propensity to generate self-harm or "
                "suicide-related content and implement targeted mitigations."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-12.10",
            description=(
                "Assess the potential for the system to be weaponised for "
                "automated hate speech generation targeting specific groups."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-12.11",
            description=(
                "Implement crisis intervention mechanisms that provide help "
                "resources when self-harm content is detected in user queries."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-12.12",
            description=(
                "Require periodic re-evaluation of content safety classifiers "
                "as adversarial techniques evolve."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-12.13",
            description=(
                "Benchmark dangerous content detection against terrorism "
                "content databases maintained by organisations such as GIFCT."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-12.14",
            description=(
                "Map potential misuse scenarios where the system assists in "
                "planning or executing violent acts."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-12.15",
            description=(
                "Implement context-aware safety systems that consider the "
                "cumulative pattern of a user's requests, not just individual queries."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-12.16",
            description=(
                "Establish coordination with counter-terrorism and law "
                "enforcement agencies for intelligence sharing on AI misuse."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
        ActionItem(
            id="GAI-12.17",
            description=(
                "Evaluate whether the model can be used to automate "
                "radicalisation pipelines or extremist recruitment campaigns."
            ),
            rmf_function=NistAiRmfFunction.MAP,
        ),
        ActionItem(
            id="GAI-12.18",
            description=(
                "Measure user trust calibration: ensure users do not over-trust "
                "the system's safety filters and neglect their own judgment."
            ),
            rmf_function=NistAiRmfFunction.MEASURE,
        ),
        ActionItem(
            id="GAI-12.19",
            description=(
                "Implement geolocation-aware content policies that comply "
                "with local regulations on violent and hateful content."
            ),
            rmf_function=NistAiRmfFunction.MANAGE,
        ),
        ActionItem(
            id="GAI-12.20",
            description=(
                "Document the organisation's approach to balancing free "
                "expression with safety in content generation policies."
            ),
            rmf_function=NistAiRmfFunction.GOVERN,
        ),
    ],
)


# ---------------------------------------------------------------------------
# Consolidated registry
# ---------------------------------------------------------------------------

RISK_CATEGORIES: dict[str, RiskCategory] = {
    "GAI-1": CBRN_INFORMATION,
    "GAI-2": CONFABULATION,
    "GAI-3": DATA_PRIVACY,
    "GAI-4": ENVIRONMENTAL_IMPACT,
    "GAI-5": HARMFUL_BIAS,
    "GAI-6": HUMAN_AI_CONFIGURATION,
    "GAI-7": INFORMATION_INTEGRITY,
    "GAI-8": INFORMATION_SECURITY,
    "GAI-9": INTELLECTUAL_PROPERTY,
    "GAI-10": OBSCENE_CONTENT,
    "GAI-11": VALUE_CHAIN,
    "GAI-12": DANGEROUS_CONTENT,
}

# Build a flat lookup of all action items keyed by their ID.
_ACTION_ITEM_INDEX: dict[str, tuple[RiskCategory, ActionItem]] = {}
for _cat in RISK_CATEGORIES.values():
    for _action in _cat.action_items:
        _ACTION_ITEM_INDEX[_action.id] = (_cat, _action)


# ---------------------------------------------------------------------------
# Keyword-based heuristic mapping from findings to risk categories
# ---------------------------------------------------------------------------

_CATEGORY_KEYWORDS: dict[str, list[str]] = {
    "GAI-1": [
        "cbrn", "chemical", "biological", "radiological", "nuclear",
        "bioweapon", "nerve agent", "synthesis route", "pathogen",
        "enrichment", "precursor chemical",
    ],
    "GAI-2": [
        "hallucination", "confabulation", "fabricat", "factual",
        "misinformation", "incorrect output", "false claim",
        "grounding", "faithfulness",
    ],
    "GAI-3": [
        "privacy", "personal data", "pii", "data protection", "gdpr",
        "ccpa", "memorisation", "data extraction", "consent",
        "data retention", "data minimisation",
    ],
    "GAI-4": [
        "environmental", "carbon", "energy consumption", "power usage",
        "sustainability", "carbon footprint", "water usage", "gpu",
        "computational cost", "green ai",
    ],
    "GAI-5": [
        "bias", "fairness", "discrimination", "homogenisation",
        "stereotype", "disparate impact", "demographic",
        "representation", "equity", "prejudice",
    ],
    "GAI-6": [
        "human oversight", "human-in-the-loop", "automation bias",
        "over-reliance", "human control", "autonomy", "human-ai",
        "de-skilling", "human review", "override",
    ],
    "GAI-7": [
        "disinformation", "deepfake", "synthetic media", "fake news",
        "information integrity", "watermark", "provenance",
        "manipulation", "influence operation", "impersonation",
    ],
    "GAI-8": [
        "prompt injection", "model extraction", "data poisoning",
        "adversarial", "jailbreak", "system prompt leak",
        "information security", "side channel", "evasion",
        "backdoor", "model theft",
    ],
    "GAI-9": [
        "intellectual property", "copyright", "licence", "license",
        "trademark", "patent", "plagiarism", "fair use",
        "attribution", "infringement",
    ],
    "GAI-10": [
        "obscene", "degrading", "abusive", "csam", "sexual",
        "explicit", "harassment", "hate speech", "offensive",
        "non-consensual", "pornograph",
    ],
    "GAI-11": [
        "supply chain", "value chain", "third-party", "vendor",
        "dependency", "plugin", "sbom", "model card",
        "component", "integration", "upstream",
    ],
    "GAI-12": [
        "violent", "dangerous", "weapon", "wmd", "terrorism",
        "radicalisation", "self-harm", "suicide", "extremis",
        "hateful", "incitement", "explosive",
    ],
}


# ---------------------------------------------------------------------------
# Public API
# ---------------------------------------------------------------------------


def get_risk_category(category_id: str) -> RiskCategory | None:
    """Look up a NIST AI 600-1 risk category by its identifier.

    Args:
        category_id: The category identifier (e.g. ``"GAI-1"``).  The lookup
            is case-insensitive and tolerates leading/trailing whitespace.

    Returns:
        The corresponding :class:`RiskCategory`, or ``None`` if the
        identifier is not recognised.
    """
    return RISK_CATEGORIES.get(category_id.strip().upper())


def get_action_item(action_id: str) -> ActionItem | None:
    """Look up an action item by its identifier.

    Args:
        action_id: The action item identifier (e.g. ``"GAI-1.01"``).

    Returns:
        The corresponding :class:`ActionItem`, or ``None`` if the
        identifier is not recognised.
    """
    entry = _ACTION_ITEM_INDEX.get(action_id.strip())
    return entry[1] if entry else None


def map_findings(findings: list[Finding]) -> dict[str, list[Finding]]:
    """Group a list of findings by their NIST AI 600-1 risk category.

    Uses a keyword-based heuristic to associate each finding with relevant
    risk categories based on the finding's title, description, and existing
    framework mappings.

    Args:
        findings: Security findings to categorise.

    Returns:
        A dictionary whose keys are NIST AI 600-1 risk category identifiers
        (e.g. ``"GAI-1"``) and whose values are the lists of findings
        mapped to that category.
    """
    grouped: dict[str, list[Finding]] = {}
    for finding in findings:
        searchable_text = (
            f"{finding.title} {finding.description} "
            f"{' '.join(finding.owasp_llm)} "
            f"{' '.join(finding.owasp_agentic)} "
            f"{' '.join(finding.nist_ai_rmf)}"
        ).lower()

        for category_id, keywords in _CATEGORY_KEYWORDS.items():
            for keyword in keywords:
                if keyword in searchable_text:
                    grouped.setdefault(category_id, []).append(finding)
                    break  # Only map once per category per finding

    return grouped


def evaluate_nist_600_1(
    findings: list[Finding],
    agent_results: list[AgentResult] | dict[str, AgentResult],
) -> ComplianceChecklist:
    """Evaluate findings against NIST AI 600-1 risk categories.

    Produces a :class:`~aisec.core.models.ComplianceChecklist` with one
    check item per risk category.  Each item's status is determined by
    whether findings map to that category:

    - ``"fail"`` -- one or more HIGH or CRITICAL findings mapped.
    - ``"partial"`` -- only MEDIUM, LOW, or INFO findings mapped.
    - ``"pass"`` -- no findings mapped to this category.

    Args:
        findings: All security findings from the scan.
        agent_results: Results from all agents (used for metadata and
            coverage assessment).

    Returns:
        A :class:`ComplianceChecklist` for the NIST AI 600-1 framework.
    """
    category_findings = map_findings(findings)

    # Also map findings from agent results that might not be in the
    # deduplicated list
    all_agent_findings: list[Finding] = []
    results_iter = (
        agent_results.values() if isinstance(agent_results, dict) else agent_results
    )
    for result in results_iter:
        all_agent_findings.extend(result.findings)
    agent_category_findings = map_findings(all_agent_findings)

    # Merge agent findings into category findings
    for cat_id, agent_f_list in agent_category_findings.items():
        existing_ids = {
            f.id for f in category_findings.get(cat_id, [])
        }
        for f in agent_f_list:
            if f.id not in existing_ids:
                category_findings.setdefault(cat_id, []).append(f)

    items: list[ComplianceCheckItem] = []
    for category_id, category in RISK_CATEGORIES.items():
        mapped = category_findings.get(category_id, [])

        if not mapped:
            status = "pass"
            evidence = f"No findings mapped to {category.name}."
        else:
            # Check severity of mapped findings
            has_critical_or_high = any(
                f.severity in (Severity.CRITICAL, Severity.HIGH)
                for f in mapped
            )
            if has_critical_or_high:
                status = "fail"
                severity_counts = _count_severities(mapped)
                evidence = (
                    f"{len(mapped)} finding(s) mapped to {category.name}: "
                    f"{severity_counts}. Immediate action required."
                )
            else:
                status = "partial"
                severity_counts = _count_severities(mapped)
                evidence = (
                    f"{len(mapped)} finding(s) mapped to {category.name}: "
                    f"{severity_counts}. Review recommended."
                )

        items.append(
            ComplianceCheckItem(
                id=category_id,
                article=f"NIST AI 600-1 {category_id}",
                requirement=category.name,
                status=status,
                evidence=evidence,
                related_findings=[f.id for f in mapped],
            )
        )

    total = len(items)
    passed = sum(1 for i in items if i.status == "pass")
    failed = sum(1 for i in items if i.status == "fail")
    not_applicable = sum(1 for i in items if i.status == "n/a")

    return ComplianceChecklist(
        framework_name="NIST AI 600-1 (Generative AI Profile)",
        total_checks=total,
        passed=passed,
        failed=failed,
        not_applicable=not_applicable,
        items=items,
    )


def get_action_items_by_function(
    rmf_function: NistAiRmfFunction,
) -> list[ActionItem]:
    """Return all action items mapped to a specific NIST AI RMF function.

    Args:
        rmf_function: The RMF function to filter by.

    Returns:
        A list of :class:`ActionItem` instances mapped to the given function.
    """
    return [
        action
        for _cat, action in _ACTION_ITEM_INDEX.values()
        if action.rmf_function == rmf_function
    ]


def get_action_items_for_category(category_id: str) -> list[ActionItem]:
    """Return all action items for a specific risk category.

    Args:
        category_id: The risk category identifier (e.g. ``"GAI-1"``).

    Returns:
        A list of :class:`ActionItem` instances for the category, or an
        empty list if the category is not recognised.
    """
    category = get_risk_category(category_id)
    if category is None:
        return []
    return list(category.action_items)


def get_remediation_actions(
    findings: list[Finding],
) -> dict[str, list[ActionItem]]:
    """Determine recommended remediation actions for a set of findings.

    Maps findings to NIST AI 600-1 risk categories and returns the
    corresponding action items grouped by category.

    Args:
        findings: Security findings requiring remediation.

    Returns:
        A dictionary mapping risk category identifiers to lists of
        recommended :class:`ActionItem` instances.
    """
    category_findings = map_findings(findings)
    remediation: dict[str, list[ActionItem]] = {}
    for category_id in category_findings:
        category = RISK_CATEGORIES.get(category_id)
        if category is not None:
            remediation[category_id] = list(category.action_items)
    return remediation


def get_summary_statistics() -> dict[str, Any]:
    """Return summary statistics about the NIST AI 600-1 risk catalogue.

    Returns:
        A dictionary with counts of categories, action items, and breakdowns
        by RMF function.
    """
    total_actions = sum(
        len(cat.action_items) for cat in RISK_CATEGORIES.values()
    )
    by_function: dict[str, int] = {
        func.value: 0 for func in NistAiRmfFunction
    }
    for cat in RISK_CATEGORIES.values():
        for action in cat.action_items:
            by_function[action.rmf_function.value] += 1

    return {
        "total_categories": len(RISK_CATEGORIES),
        "total_action_items": total_actions,
        "action_items_by_function": by_function,
        "categories": [
            {
                "id": cat.id,
                "name": cat.name,
                "action_item_count": len(cat.action_items),
            }
            for cat in RISK_CATEGORIES.values()
        ],
    }


# ---------------------------------------------------------------------------
# Private helpers
# ---------------------------------------------------------------------------


def _count_severities(findings: list[Finding]) -> str:
    """Build a human-readable severity count string."""
    counts: dict[Severity, int] = {}
    for f in findings:
        counts[f.severity] = counts.get(f.severity, 0) + 1
    parts: list[str] = []
    for sev in (Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM,
                Severity.LOW, Severity.INFO):
        count = counts.get(sev, 0)
        if count > 0:
            parts.append(f"{count} {sev.value}")
    return ", ".join(parts) if parts else "none"
